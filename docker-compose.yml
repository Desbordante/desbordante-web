version: "3.3"
services:
  postgres:
    image: postgres:14.1
    environment:
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
      POSTGRES_USER: "${POSTGRES_USER}"
      POSTGRES_DB: "${POSTGRES_DB}"
    expose:
      - "5432"
    networks:
      - network
    restart: always
    volumes:
      - postgres-data:/var/lib/postgresql/data
    logging:
      driver: 'json-file'
      options:
        max-size: 20m

  client:
    build:
      context: ./web-app/
      dockerfile: Dockerfile-client
    ports:
      - "3000:80"
    expose:
      - "4000"
    environment:
      REACT_APP_HOST_SERVER_IP: ${REACT_APP_HOST_SERVER_IP}
      REACT_APP_SERVER_PORT: 5000
      REACT_APP_PASSWORD_SALT_PREFIX: ${REACT_APP_PASSWORD_SALT_PREFIX}
      REACT_APP_PASSWORD_SALT_POSTFIX: ${REACT_APP_PASSWORD_SALT_POSTFIX}
      REACT_APP_SERVER_PROTOCOL: ${REACT_APP_SERVER_PROTOCOL}
      PORT: 3000
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf
      - ./grafana-users:/etc/nginx/grafana_passw
    depends_on:
      - "postgres"
      - "server"
    networks:
      - network
    restart: always
    logging:
      driver: 'json-file'
      options:
        max-size: 20m

  server:
    build:
      context: ./web-app/
      dockerfile: Dockerfile-server
    environment:
      DB_NAME: "${POSTGRES_DB}"
      DB_USER: "${POSTGRES_USER}"
      DB_PASSWORD: "${POSTGRES_PASSWORD}"
      DB_HOST: postgres
      DB_PORT: 5432
      DB_FORCE_TABLES_RECREATION: ${DB_FORCE_TABLES_RECREATION}
      NODE_ENV: ${NODE_ENV}
      SERVER_PORT: 5000
      SERVER_HOST: 0.0.0.0
      KAFKA_HOST: kafka
      KAFKA_SERVER_PORT: 9092
      KAFKA_ADMIN_CLIENT_ID: "${KAFKA_ADMIN_CLIENT_ID}"
      KAFKA_TOPIC_NAME: tasks
      MAX_THREADS_COUNT: 8
      SECRET_KEY: ${SECRET_KEY}
      USE_NODEMAILER: ${USE_NODEMAILER}
      NODEMAILER_EMAIL: ${NODEMAILER_EMAIL}
      NODEMAILER_PWD: ${NODEMAILER_PWD}

    ports:
      - "5000:5000"
    depends_on:
      - postgres
      - kafka
    volumes:
      - uploads:/server/uploads/
      - datasets:/server/build/target/inputData/
    networks:
      - network
    restart: always
    logging:
      driver: 'json-file'
      options:
        max-size: 20m

  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    expose:
      - "2181"
    environment:
      ALLOW_ANONYMOUS_LOGIN: 'yes'
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - network
    restart: always
    volumes:
       - ./volumes/logs/zk/:/var/lib/zookeeper/log
       - ./volumes/data/zk/:/var/lib/zookeeper/data
    logging:
      driver: 'json-file'
      options:
        max-size: 20m

  kafka:
    image: confluentinc/cp-kafka:6.2.0
    expose:
      - '9092'
      - '1234'
    links:
      - 'prometheus'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      ALLOW_PLAINTEXT_LISTENER: 'yes'
      KAFKA_LISTENERS: 'PLAINTEXT://:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_OPTS: '-javaagent:/opt/prometheus/jmx_prometheus_javaagent-0.15.0.jar=1234:/opt/prometheus/kafka_broker.yml'
    depends_on:
      - zookeeper
    networks:
      - network
    restart: always
    volumes:
      - ./volumes/logs/kafka/:/var/log/kafka
      - ./volumes/data/kafka/:/var/lib/kafka/data
      - ./web-app/prometheus/kafka/:/opt/prometheus/
    logging:
      driver: 'json-file'
      options:
        max-size: 20m

  python-consumer:
    build:
      context: ./python-consumer
      dockerfile: Dockerfile
    depends_on:
      - kafka
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - uploads:/server/uploads/
    networks:
      - network
    environment:
      TIMELIMIT: ${CONSUMER_TL_SEC}
      MAX_RAM: ${CONSUMER_ML_MB}
      KAFKA_HOST: kafka
      KAFKA_PORT: 9092
      MAX_ACTIVE_TASKS: ${MAX_ACTIVE_TASKS}
      DOCKER_NETWORK: desbordante_network
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: "${POSTGRES_USER}"
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
      POSTGRES_DBNAME: "${POSTGRES_DB}"
      DB_TASKS_TABLE_NAME: "TasksState"
    restart: always
    logging:
      driver: 'json-file'
      options:
        max-size: 20m

  prometheus:
    image: prom/prometheus
    volumes:
      - ./web-app/prometheus/:/etc/prometheus/
    networks:
      - network
    expose:
      - '9090'
    links:
      - 'grafana'

  nginx-metrics:
    image: nginx/nginx-prometheus-exporter
    command: -nginx.scrape-uri=http://client:4000/nginx_status
    restart: always
    networks:
      - network
    expose:
      - '9113'
    links:
      - 'prometheus'

  node-exporter:
    image: prom/node-exporter
    container_name: monitoring_node_exporter
    restart: always
    networks:
      - network
    expose:
      - 9100
    links:
      - 'prometheus'
    volumes:
      - '/:/host:ro,rslave'
    command:
      - '--path.rootfs=/host'
      
    pid: host

  cadvisor:
    image: google/cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    restart: always
    privileged: true
    networks:
      - network
    expose:
      - '8080'
    links:
      - 'prometheus'

  grafana:
    image: grafana/grafana
    networks:
      - network
    expose:
      - '3000'
    volumes:
      - ./volumes/data/grafana/:/var/lib/grafana/
      - ./web-app/grafana/:/etc/grafana/

networks:
  network:
volumes:
  uploads:
    driver: local
    driver_opts:
      type: 'volume'
      o: 'bind'
      device: '${PWD}/volumes/uploads/'
  postgres-data:
    driver: local
    driver_opts:
      type: 'volume'
      o: 'bind'
      device: '${PWD}/volumes/postgres-data/'
  datasets:
    driver: local
    driver_opts:
      type: 'volume'
      o: 'bind'
      device: '${PWD}/volumes/datasets/'